# Production Environment Configuration
# Use Docker service names for container networking

# Production mode
DEBUG=false
LOG_LEVEL=INFO

# Database Configuration (Docker service names)
NEO4J_URI=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
WEAVIATE_URL=http://weaviate:8080

# LLM Provider Configuration
# Ollama (Local)
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=openhermes2.5-mistral

# Cloud Provider API Keys (Set via Docker secrets or environment)
# OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
# GEMINI_API_KEY=${GEMINI_API_KEY}
# ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}

# LLM Provider Settings
DEFAULT_LLM_PROVIDER=ollama
ENABLE_PROVIDER_FAILOVER=true
MAX_COST_PER_QUERY=0.05

# RAG Configuration
MAX_CONTEXT_TOKENS=5000
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Processing Configuration
MAX_CONCURRENT_REQUESTS=50
RESPONSE_TIMEOUT=60

# Cache Configuration
ENABLE_CACHING=true
CACHE_TTL=7200