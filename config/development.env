# Development Environment Configuration
# Copy this file to .env in project root for local development

# Debug mode
DEBUG=true
LOG_LEVEL=DEBUG

# Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
WEAVIATE_URL=http://localhost:8080

# LLM Provider Configuration
# Ollama (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=openhermes2.5-mistral

# Cloud Provider API Keys (Optional - uncomment and add your keys)
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# GEMINI_API_KEY=your_google_gemini_api_key_here  
# ANTHROPIC_API_KEY=your_anthropic_claude_api_key_here

# LLM Provider Settings
DEFAULT_LLM_PROVIDER=ollama
ENABLE_PROVIDER_FAILOVER=true
MAX_COST_PER_QUERY=0.10

# RAG Configuration
MAX_CONTEXT_TOKENS=5000
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Processing Configuration
MAX_CONCURRENT_REQUESTS=10
RESPONSE_TIMEOUT=30

# Cache Configuration
ENABLE_CACHING=true
CACHE_TTL=3600